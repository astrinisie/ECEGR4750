{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "This material is adapted from: https://machinelearningmastery.com/machine-learning-in-python-step-by-step/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "```\n",
    "0. Ensure that Python version > 3.8.0 is installed.\n",
    "1. Setup a virtual environment, called '.venv'\n",
    "    a. In your terminal: $ python -m venv .venv\n",
    "2. Activate the virtual environment\n",
    "    a. In Powershell or Windows CMD: $ .venv\\Scripts\\activate\n",
    "    b. In Linux: $ source .venv/bin/activate\n",
    "3. Install all necessary librarires\n",
    "    a. $ pip install -r requirements.txt\n",
    "    b. Upgrade pip if necessary: $ python -m pip install --upgrade pip\n",
    "4. Open up Jupyter Notebook\n",
    "    a. $ jupyter notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all packages import without error\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "#our model imports to use later\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "print(len(dataset))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze dataset\n",
    "\n",
    "In any machine learning project, it is absolutely critical to understand the distribution of your variables of interest. Not only will it give you clues about the relationships present in your dataset, it will also help you select the most appropriate machine learning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution - is it balanced or unbalanced?\n",
    "print(dataset.groupby('class').size())\n",
    "classes = dataset['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use plenty of built in functions out there to assist us\n",
    "\n",
    "pd.plotting.scatter_matrix(dataset, figsize = (10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it may be handy to visualize the distribution of our values for each class as well\n",
    "\n",
    "# the following code iterates through each class and plots a histogram of each feature\n",
    "fig, axs = plt.subplots(1,3, figsize = (15,5))\n",
    "plot_id = 0\n",
    "for cls in classes: # for each class\n",
    "    for feature in dataset.columns[:-1]: # for each feature\n",
    "        axs[plot_id].hist(\n",
    "            dataset.loc[dataset['class'] == cls][feature],\n",
    "            bins = np.arange(0,8,0.5)\n",
    "            ) \n",
    "        axs[plot_id].set_ylim(0,40)\n",
    "        axs[plot_id].set_xlabel(cls)\n",
    "    plot_id += 1\n",
    "axs[-1].legend(dataset.columns[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what relationships can we spot within our feature set?\n",
    "# are there any clear correlations between our distribution of features and our classes? \n",
    "# what exactly is petal and sepal length? understanding what the data represents can help you massively later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the problem\n",
    "\n",
    "Given a set of petal and sepal dimensions, predict the type of iris. Simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and validation sets\n",
    "\n",
    "In practice, splitting is very important. Understanding how your dataset is sampled from the population is key to deciding on a splitting strategy. If you sample your irises from one garden only, then no matter how you split it, you can never say your model generalizes outside of that garden. \n",
    "\n",
    "For the sake of argument, let's say that this dataset is extracted from two gardens, garden 1 and garden 2. Then, we can split by garden and answer the question \"does training on garden 1 let me predict irises in garden 2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset randomly\n",
    "dataset = dataset.sample(frac=1, random_state=42) #set the seed to make it repeatable\n",
    "\n",
    "#split the dataset in half and label it garden 1 and garden 2\n",
    "df_garden1 = dataset.iloc[:75]\n",
    "df_garden2 = dataset.iloc[75:]\n",
    "\n",
    "#is class balance going to be affected?\n",
    "\n",
    "#split up each dataframe into inputs and class labels\n",
    "x_train = df_garden1.loc[:, df_garden1.columns != 'class']\n",
    "y_train = df_garden1['class']\n",
    "\n",
    "print(f'x_train has shape {x_train.shape} and y_train has shape {y_train.shape}')\n",
    "\n",
    "x_val = df_garden2.loc[:, df_garden2.columns != 'class']\n",
    "y_val = df_garden2['class']\n",
    "\n",
    "print(f'x_val has shape {x_val.shape} and y_val has shape {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply some models\n",
    "\n",
    "We will use several different classic machine learning techniques to predict the iris class, given the petal and sepal features.\n",
    "\n",
    "But first, we need to decide on our metric. Because this is a classification problem, we have several options.\n",
    "\n",
    "- Accuracy: what percentage of examples were correctly identified?\n",
    "- Precision: given every time a certain class was predicted, how many times was it correct?\n",
    "- Recall: how many times was a class correctly predicted out of all its instances?\n",
    "\n",
    "Accuracy is the most simple, but can obscure failures of our model (particularly if classes are imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['LR'] = {'model': LogisticRegression(solver='liblinear', multi_class='ovr')}\n",
    "models['LDA'] = {'model': LinearDiscriminantAnalysis()}\n",
    "models['KNN'] = {'model': KNeighborsClassifier()}\n",
    "models['CART'] = {'model': DecisionTreeClassifier()}\n",
    "models['NB'] = {'model': GaussianNB()}\n",
    "models['SVM'] = {'model': SVC(gamma='auto')}\n",
    "\n",
    "# evaluate each model in turn\n",
    "for name, m_dict in models.items():\n",
    "    m_dict['results'] = m_dict['model'].fit(x_train, y_train).predict(x_val) #fit and predict with the model\n",
    "    m_dict['accuracy'] = sum(m_dict['results'] == y_val) / len(y_val) #calculate accuracy\n",
    "    print(name, '{:.3f}'.format(m_dict['accuracy']))\n",
    "\n",
    "    #log precision and recall metrics as well for each class\n",
    "    for cls in classes:\n",
    "        m_dict[f'{cls}_precision'] = precision_score(\n",
    "            m_dict['results'] == cls, \n",
    "            y_val == cls, \n",
    "            average = 'binary'\n",
    "            )\n",
    "        m_dict[f'{cls}_recall'] = recall_score(\n",
    "            m_dict['results'] == cls, \n",
    "            y_val == cls, \n",
    "            average = 'binary'\n",
    "            )\n",
    "        m_dict[f'{cls}_accuracy'] = accuracy_score(\n",
    "            m_dict['results'] == cls, \n",
    "            y_val == cls, \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize by class\n",
    "Are any classes more difficult to predict than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try seeing what different metrics look like for different classes\n",
    "metric = 'accuracy'\n",
    "bar_offset = -.2\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "for cls in classes:\n",
    "    #practice list comprehension to obtain results from the dict\n",
    "    vals = [m_dict[cls + '_' + metric] for _,m_dict in models.items()]\n",
    "\n",
    "    #make a bar plot\n",
    "    plt.bar(np.array(range(len(models))) + bar_offset, vals, width = 0.2)\n",
    "    plt.xticks(range(len(models)), labels = list(models.keys()), fontsize = 20)\n",
    "\n",
    "    bar_offset += 0.2\n",
    "\n",
    "plt.legend(dataset['class'].unique(), loc = 'lower right', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow up problems\n",
    "\n",
    "1. Which feature in the dataset is most useful for prediction? How would you test that?\n",
    "2. How does the quantity of training data affect performance metrics? Which methods are capable of learning on less data?\n",
    "3. What other forms of data could you collect from garden1 to improve your model?\n",
    "4. What does it mean to have high recall and low precision? If I develop a computer vision model that warns a driver of obstacles in the road, do I care more about precision or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
