{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: Part 2 - Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a dataloader\n",
    "\n",
    "So far, we have manually iterated through our datasets to train our models. As you can tell, it is very clunky if you decide to use batches of data, or would like to randomize your data. A `dataloader` is a pytorch class that wraps a dataset. Today, we will write our own version of it, so we can streamline testing different training strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal version\n",
    "\n",
    "Let's first just make a minimal version. It is a class that will accept a *training/val/test dataset* and will simply pass us entries from that dataset on demand, one at a time.\n",
    "\n",
    "We will make use of an `iter` object, which is a generator that can produce an output by calling `next(iter)` on it. This is a \"lazy\" function that only loads data into memory when we call it, which becomes very efficient with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of constructing an iterator\n",
    "random_objects = ['chair', 'doorknob', 'stereo', 'paper airplane']\n",
    "iterator = iter(random_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chair'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call next on the iterator repeatedly\n",
    "next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've started the code here. Fill in the missing part 'generate_iter' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataloader():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.iter = self.generate_iter()\n",
    "\n",
    "    def generate_iter(self):\n",
    "        batches = []\n",
    "        for idx in range(self.x.shape[0]):\n",
    "            batches.append(\n",
    "                {\n",
    "                    'x':self.x[idx],\n",
    "                    'y':self.y[idx],\n",
    "                }\n",
    "            ) \n",
    "        return iter(batches)\n",
    "\n",
    "    def fetch_row(self):\n",
    "        return next(self.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in our processed data, and try fetching data from it using our dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load('data/wages_processed.pt')\n",
    "train_dataloader = SimpleDataloader(data_dict['x_train'],data_dict['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([-0.3905,  0.4840, -1.3102,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000]),\n",
       " 'y': tensor([0.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.fetch_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make a dataloader really useful, we should allow ourselves to set a batch size, so every time we call on our iterator, it will return a whole batch of data.\n",
    "\n",
    "Take a look in `model/dataloader.py`. I have included just the framework of the class there, with descriptions of what each function should do. Fill it in yourself, and keep in mind these constraints:\n",
    "\n",
    "- If the iterator reaches the end, it should restart\n",
    "- Data should be randomized each time the iterator resets\n",
    "- Any batch size should be valid\n",
    "- All data needs to be iterated through before resetting\n",
    "\n",
    "Use the below cell to test out your new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_batch': tensor([[-0.3905,  0.4840, -1.3102,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "           1.0000]]),\n",
       " 'y_batch': tensor([[0.]]),\n",
       " 'batch_idx': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.dataloader_Solution import CustomDataloader\n",
    "\n",
    "data_dict = torch.load('data/wages_processed.pt')\n",
    "train_dataloader = CustomDataloader(data_dict['x_train'],data_dict['y_train'])\n",
    "train_dataloader.fetch_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
