{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "The most widely used library for neural networks is `torch`. Let's walk through the basics of building a simple fully connected neural network with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install `torch` without any addons like GPU support (via nvidia's CUDA toolkits) or particular libraries that make certain operations more efficient. Management of data and models across devices is its own subject, so we will only use the CPU-based version of `torch`. For the other versions, check here: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# install pytorch by running `pip install torch`\n",
    "import torch\n",
    "\n",
    "# check that it imports and get the version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will grab a dataset we are familiar with from sklearn, and prepare it to be used by our `torch` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (265, 10) y train: (265,)\n",
      "x val:  (88, 10) y train: (88,)\n",
      "x test:  (89, 10) y test: (89,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load our data\n",
    "dataset = load_diabetes()\n",
    "x = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "# split train and val\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, train_size = 0.6)\n",
    "\n",
    "# split again to get a test set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, train_size=0.5)\n",
    "\n",
    "print(\"x train: \",x_train.shape, \"y train:\", y_train.shape)\n",
    "print(\"x val: \",x_val.shape, \"y train:\", y_val.shape)\n",
    "print(\"x test: \",x_test.shape, \"y test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to check to see if our data has any features that are scaled abnormally. Ideally, all our features lie in a -1 to 1 range, where our model will be able to handle it. Features that are too large or small in scale can complicate training a neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0, figsize=(10,4))\n",
    "plt.title('All training values')\n",
    "plt.hist(x_train.flatten(), bins = np.arange(-1,1,0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note about test data: We have added a new split to our data, which we can now call our \"test\" data. When we train a neural network, we usually look at both the training loss and validation loss during training. We would like our validation loss to be close as possible to our training loss, because it indicates our model is not simply \"memorizing\" the training data. However, we make decisions about our model's hyperparameters (like learning rate, choice of activation functions, width and depth of layers, etc) based on our performance on validation data. This is a kind of overfitting, and so we need a truly unseen dataset to test our model on after training, hence, \"test\" data.\n",
    "\n",
    "\n",
    "---------------------\n",
    "\n",
    "\n",
    "`torch` provides some neat functionality. As input, it wants our data to be of type `torch.Tensor`, and all operations performed on that tensor must also be a `torch` operation. This is because `torch` can do automatic differentiation of almost *any* `torch` operation. Often, simply replacing `numpy` with `torch` is sufficient. So `np.add` could simply be written as `torch.add`.\n",
    "\n",
    "So, we should transform our data into `torch.Tensors`, which thankfully is very easy to do. The data should stay in this format until it has passed entirely through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train <class 'numpy.ndarray'>\n",
      "Type of x_train <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of x_train',type(x_train))\n",
    "x_train, x_val, x_test = torch.Tensor(x_train), torch.Tensor(x_val), torch.Tensor(x_test)\n",
    "y_train, y_val, y_test = torch.Tensor(y_train), torch.Tensor(y_val), torch.Tensor(y_test)\n",
    "print('Type of x_train',type(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "We will now construct our model class and call it LearningModel. This will define everything about our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LearningModel(nn.Module): # this means the class is inheriting all the class attributes of nn.Module\n",
    "    \n",
    "    # the __init__ function is called when an instance of the class is created\n",
    "    def __init__(self):\n",
    "        super(LearningModel, self).__init__() # lets us call methods from the base class, nn.Module\n",
    "\n",
    "        # now we can define our layers\n",
    "        # by prepending self to it, we are storing this as a variable of our class, that can be called elsewhere\n",
    "        self.linear1 = nn.Linear(in_features = 10, out_features = 64)\n",
    "        self.linear2 = nn.Linear(in_features = 64, out_features = 32)\n",
    "        self.linear3 = nn.Linear(in_features = 32, out_features = 1)\n",
    "\n",
    "        # our activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    # the forward function defines how the data flows through each layer of the model, and should return the model's output\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        # note that I can do any torch operation I want inside this forward function, and pytorch will automatically calculate\n",
    "        # my gradient. doesn't just have to be torch.nn layers!\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([1])\n",
      "Parameter containing:\n",
      "tensor([-0.0723], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# instantiate our model\n",
    "model = LearningModel() \n",
    "\n",
    "# look at the shape of our model's layers as we defined above\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "\n",
    "# look at what these random initialized parameters look like\n",
    "# we can print out the final parameter from the loop above, which is the bias term of our linear3 layer\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into training, we want to check that our model is compatible with our data. Let's make dummy data and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 10])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "model = LearningModel() \n",
    "\n",
    "# make a dummy sample the same size of our data\n",
    "x_dummy = torch.rand(1, 10) \n",
    "print(type(x_dummy), x_dummy.shape)\n",
    "\n",
    "# pass the data through the model. note that model.forward(x_dummy) can also be written as model(x_dummy)\n",
    "y_dummy = model(x_dummy)\n",
    "print(type(y_dummy), y_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x9 and 10x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# see what happens if we pass the wrong size data through. this is an error you will see a lot in model development!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m x_dummy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m y_dummy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dummy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mLearningModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x9 and 10x64)"
     ]
    }
   ],
   "source": [
    "# see what happens if we pass the wrong size data through. this is an error you will see a lot in model development!\n",
    "x_dummy = torch.rand(1, 9)\n",
    "y_dummy = model(x_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# see what happens if we pass a numpy array through\u001b[39;00m\n\u001b[1;32m      2\u001b[0m x_dummy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m y_dummy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dummy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mLearningModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ECEGR4750/ECEGR4750/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# see what happens if we pass a numpy array through\n",
    "x_dummy = np.random.normal(0, 1, (1, 9))\n",
    "y_dummy = model(x_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put some `print(x.shape)` statements in your forward function and observe how the data changes shape as it passes through the model.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:11<00:00, 16.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm # handy way to visualize long jobs. pip install tqdm if you don't have this yet\n",
    "\n",
    "# re-instantiate our model\n",
    "model = LearningModel()\n",
    "\n",
    "# define our optimizer. this is what our model will use to update its weights\n",
    "# we will use the Adam optimizer, which is a well established method https://arxiv.org/pdf/1412.6980.pdf\n",
    "# we will set the learning rate and pass our model's parameters to the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4) # set learning rate\n",
    "\n",
    "# set up our training loop. we will do SGD, so one sample at a time\n",
    "epochs = 200\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "\n",
    "    # iterate through an entire epoch of training data\n",
    "    it_loss = []\n",
    "    model.train() # setting mode of model to train\n",
    "    for idx in range(len(x_train)):\n",
    "\n",
    "        # clear out the gradient from prior backward passes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the model's prediction for that sample\n",
    "        yhat = model(x_train[idx]) \n",
    "\n",
    "        # calculate loss using MAE\n",
    "        loss = torch.mean(torch.abs(y_train[idx] - yhat))\n",
    "\n",
    "        # because loss is a tensor that passed through our model, it automatically tracks its history\n",
    "        # we can calculate the gradient quite simply\n",
    "        # this computes the gradient of the model parameters that this tensor operated with\n",
    "        loss.backward() \n",
    "\n",
    "        # this updates the model's parameters \n",
    "        optimizer.step()\n",
    "\n",
    "        # log the loss\n",
    "        # first, \"detach\" the loss from the computation graph (the thing that tracks the model parameters)\n",
    "        # second, convert it to a numpy array\n",
    "        it_loss.append(loss.detach().numpy())\n",
    "        \n",
    "\n",
    "    # calculate and append the loss for the entire epoch\n",
    "    train_loss.append(np.mean(it_loss))\n",
    "\n",
    "    # pass the validation data through the model, all at once, and calculate its loss (but DONT update weights!)\n",
    "    model.eval() # setting mode of model to eval\n",
    "    optimizer.zero_grad()\n",
    "    yhat = model(x_val)\n",
    "    loss = torch.mean(torch.abs(y_val - yhat))\n",
    "    val_loss.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training and validation loss throughout training. Because loss alone is difficult to interpret, check to see if the model's predictions are lining up reasonably with the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(val_loss[-1], train_loss[-1])\n",
    "\n",
    "plt.figure(0, figsize = (12,6))\n",
    "plt.title('Loss per epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss)\n",
    "plt.plot([v.detach().numpy() for v in val_loss])\n",
    "plt.legend([\"Training loss\",\"Validation loss\"])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,6));\n",
    "axs[0].scatter(model(x_train).detach().numpy(), y_train, color = 'blue')\n",
    "axs[0].plot([0,300],[0,300], color = 'red', linestyle = '--')\n",
    "axs[0].set_title('Training Data')\n",
    "axs[0].set_xlabel('Real')\n",
    "axs[0].set_ylabel('Predicted')\n",
    "axs[1].scatter(model(x_val).detach().numpy(), y_val, color = 'orange')\n",
    "axs[1].plot([0,300],[0,300], color = 'red', linestyle = '--')\n",
    "axs[1].set_title('Validation Data')\n",
    "axs[1].set_xlabel('Real')\n",
    "axs[1].set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! First model trained!\n",
    "\n",
    "How many times were your model's parameters updated?\n",
    "\n",
    "- answer: if doing SGD like above, its len(train_data) * num_epochs\n",
    "\n",
    "How should you interpret the training and validation loss curves above?\n",
    "\n",
    "- answer: when train_loss < val_loss, the model is overfit to training data. the point at which validation loss is at its minimum is one criteria to choose when to stop your model. this criteria can change depending on what you value about your model.\n",
    "\n",
    "------------------------------------------\n",
    "\n",
    "### Model Experimentation\n",
    "\n",
    "Take some time and experiment with a few things. With each experiment, try running the training loop with the fixed values provided above.\n",
    "\n",
    "- \"Hidden size\" of the model, or number of units in each layer (as long as input and output are right sizes, nothing else matters)\n",
    "- Add or reduce the number of layers in the model.\n",
    "- Try other activation functions, like `nn.ELU` or `nn.Tanh` or anything from this https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "- Try implementing dropout in the model with `nn.Dropout`. Every forward pass, it chooses a subset of units in the tensor to zero out. This mitigates overfitting by preventing the model from effectively memorizing the data. Note that when it comes time to actually predict your data outside of training, you should call `model.eval()` to turn dropout off. `model.train()` will turn it back on.\n",
    "\n",
    "### Training Experimentation\n",
    "\n",
    "You can also experiment with the training routine. Once you have found a model architecture you like, try this out:\n",
    "\n",
    "- `torch.optim.Adam` is just one optimizer, you can try others found here https://pytorch.org/docs/stable/optim.html.\n",
    "- Learning rate has a huge impact on training. Try setting it anywhere from 1e-1 to 1e-6 and see how it changes convergence.\n",
    "- Batch gradient descent changes how quickly the model learns. This dataset should be small enough to fit into memory all at once, so safe to pass the entire train set in at once.\n",
    "- Try implementing an \"early stopping\" routine, where training is aborted once some criteria is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this space for experimentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set\n",
    "\n",
    "You now have a cool model that you have tinkered on and found a set of hyperparameters that give you good performance on your validation data. Now, we need to see how well the model performs on 100% unseen data, our test data.\n",
    "\n",
    "Looking at this test data beforehand can bias us dramatically. On a simple dataset like this, hyperparameters may not have a huge impact on the overall model, so the potential negative effect is small. On harder datasets with more complex models, choices of parameters can have a make or break impact on if the model will actually succeed in a real life application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how our model performs on training data, validation data, and test data\n",
    "yhat_train = model(x_train).detach().numpy()\n",
    "yhat_val = model(x_val).detach().numpy()\n",
    "yhat_test = model(x_test).detach().numpy()\n",
    "\n",
    "print('Train MAE:', np.mean(np.abs(yhat_train - y_train.numpy())))\n",
    "print('Val MAE:', np.mean(np.abs(yhat_val - y_val.numpy())))\n",
    "print('Test MAE:', np.mean(np.abs(yhat_test - y_test.numpy())))\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18,6));\n",
    "\n",
    "axs[0].scatter(yhat_train, y_train, color = 'blue')\n",
    "axs[0].plot([0,300],[0,300], color = 'red', linestyle = '--')\n",
    "axs[0].set_title('Training Data')\n",
    "axs[0].set_xlabel('Real')\n",
    "axs[0].set_ylabel('Predicted')\n",
    "\n",
    "axs[1].scatter(yhat_val, y_val, color = 'orange')\n",
    "axs[1].plot([0,300],[0,300], color = 'red', linestyle = '--')\n",
    "axs[1].set_title('Validation Data')\n",
    "axs[1].set_xlabel('Real')\n",
    "axs[1].set_ylabel('Predicted')\n",
    "\n",
    "axs[2].scatter(yhat_test, y_test, color = 'green')\n",
    "axs[2].plot([0,300],[0,300], color = 'red', linestyle = '--')\n",
    "axs[2].set_title('Test Data')\n",
    "axs[2].set_xlabel('Real')\n",
    "axs[2].set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
