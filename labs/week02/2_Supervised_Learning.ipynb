{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Regression\n",
    "Week 2 Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) OLS\n",
    "Taken from https://github.com/jermwatt/machine_learning_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "csvname =  'student_debt_data.csv'\n",
    "data = np.loadtxt(csvname,delimiter=',')\n",
    "\n",
    "# extract input - for this dataset, these are times\n",
    "x = data[:,0]\n",
    "\n",
    "# extract output - for this dataset, these are total student debt\n",
    "y = data[:,1]\n",
    "\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Find $\\theta$ that minimizes the sum-of-squared error cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we have to create an array of x0 that is all 1. Remember from the lecture we have $h = theta_0 + theta_i * x_1 + ... + theta_n * x_n. The x_0 term is 1.\n",
    "# I completely missed this part in the lecture when we wrote down X in matrix form, as well as when we were going through the lab just now. This was why we got a huge value\n",
    "# of theta that resulted in a prediction with enormous error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Plot x, y, and the prediction function with $\\theta$ found in Question 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting x, y, and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Plot the error between prediction and actual y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error between prediction and actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) LMS\n",
    "Let's implement least means square fitting manually, and check to see how different parameters affect learning\n",
    "\n",
    "### a) Create a pseudo-random dataset\n",
    "Instead of using \"real\" data, in this exercise we will fabricate a simple data with correlation between x and y to further understand input and output relationships and how a model can predict them.\n",
    "\n",
    "Given the array `x` in space $\\mathbb{R}^{\\text{nxd}}$ with `n` samples and `d` features, generate `y` such that it holds some correlation to `x`.\n",
    "\n",
    "Bonus: later on, we will dealy with arrays with more than 2D. These are called \"tensors\". A *tensor* is simple a generalized matrix that can be any dimension, not just 2D. We will stick with 2D here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "n = 30 # num samples in dataset\n",
    "d = 5 # starting very simply with 1 feature only\n",
    "NOISE_AMPLITUDE = 0.1 # how much noise to inject into dataset\n",
    "\n",
    "# Generate x values\n",
    "x = np.random.uniform(-1, 1, (n, d))\n",
    "print(f'Shape of array x is {x.shape}') # check the shape\n",
    "\n",
    "# Generate a y value that is somewhat correlated\n",
    "# There are many ways to do this, let's just write a quick rule that linearly combines the features of x and injects some noise\n",
    "# Note that we assume an intercept (bias) of 0\n",
    "theta_true = np.random.uniform(-1,1, (d))\n",
    "\n",
    "y = x @ theta_true + np.random.normal(0,NOISE_AMPLITUDE,(n)) # the `@` operator is used for numpy matrix multiplication, and is just shorthand for the dot product\n",
    "\n",
    "# Let's check the correlation to be sure\n",
    "correlations = [np.corrcoef(x[:, i], y)[0, 1] for i in range(d)] # calculate Pearson's R for each feature vector\n",
    "print(f'Correlations for each feature are {correlations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q: What happened to the correlation when noise is zero?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's increase the number of features d to 5. Pay attention to the correlation between each feature and the output y.\n",
    "Copying the cells above but with d = 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are, some features will have a large correlation whereas others may have little correlation. Note that correlation here is only checking for the existence of a *linear* relationship.\n",
    "\n",
    "*Q: If we wanted to improve our correlations, is it better to add more data or to reduce the amplitude of noise? Come up with a hypothesis and test it by tuning the parameters above. Experiment with the number of samples, features, and amplitude of noise.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 1*d))\n",
    "\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, d)) # make an iterable of colors\n",
    "\n",
    "for feature in range(d):\n",
    "    plt.subplot(1, d, feature+1)\n",
    "    plt.scatter(x[:,feature],y,color = colors[feature])\n",
    "    plt.title(f\"Feature {feature+1}\")\n",
    "    plt.xlabel(f\"$x_{feature+1}$\")\n",
    "    plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease of use later, let's wrap up our dataset generation into a function that gives us an x and y given our starting params\n",
    "\n",
    "def generate_dataset(num_feats: int, num_samples: int, noise_amp: float) -> tuple([np.ndarray, np.ndarray, np.ndarray]):\n",
    "    x = np.random.uniform(-1, 1, (num_samples, num_feats))\n",
    "    theta_true = np.random.uniform(-1,1, (num_feats))\n",
    "    y = x @ theta_true + np.random.normal(0, noise_amp, (num_samples))\n",
    "    return x, y, theta_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Least Mean Squares\n",
    "\n",
    "We will now implement LMS to see if we can recover our true theta (weights)!\n",
    "\n",
    "We can start by taking a random guess of our true theta (weights). Let's call our random starting weights `θ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.uniform(-2,2,(d)) # here, we are initializing our weights from a uniform distribution ranging from -2 to 2, but it could start from anywhere\n",
    "print(f'theta is {theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply those weights `θ` to our data `x` to calculate our predicted y, or $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = x @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define the LMS cost function. Here, our cost function we would like to minimize is the *mean squared error* between y and yhat. Let's write a function so that this is easy to compute. We will use good coding practice here as well by properly documenting our function with typings and naming our variables to be easily understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(x : np.ndarray, y : np.ndarray, theta : np.ndarray) -> np.ndarray:\n",
    "    yhat = x @ theta # apply weights to data to get prediction yhat\n",
    "    error = yhat - y # get the error\n",
    "    loss = (1 / len(y)) * np.sum(error ** 2) # mean squared error\n",
    "    return loss\n",
    "\n",
    "# test it out\n",
    "print(f'Initial loss: {mean_squared_error(x, y, theta)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do gradient descent. This is an iterative algorithm that requires us to take the partial derivative of our loss function, with respect to our parameters θ. Below is the derivation provided again for review.\n",
    "\n",
    "---\n",
    "\n",
    "#### __Cost Function__:\n",
    "\n",
    "The cost function for LMS is defined as the Mean Squared Error (MSE):\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2n} \\sum_{i=1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$\n",
    "Where:\n",
    "- $n$ is the number of data points.\n",
    "- $h_{\\theta}(x^{(i)})$ is our hypothesis or prediction for the $i^{th}$ input. \n",
    "\n",
    "---\n",
    "\n",
    "#### __Hypothesis__:\n",
    "\n",
    "Our hypothesis function is given by:\n",
    "\n",
    "$$ h_{\\theta}(x) = x \\cdot \\theta $$\n",
    "Where:\n",
    "- $x$ is our input vector.\n",
    "- $\\theta$ is our weight vector.\n",
    "\n",
    "---\n",
    "\n",
    "#### __Derivation of the Gradient__:\n",
    "\n",
    "Now, for the step-by-step derivation of the gradient:\n",
    "\n",
    "1. Start with a single example $i$ inside the summation:\n",
    "\n",
    "$$ \\text{error}^{i} = h_{\\theta}(x^{i}) - y^{i} $$\n",
    "\n",
    "2. Squared error for the $i^{th}$ example:\n",
    "\n",
    "$$ (\\text{error}^{i})^2 = (x^{i} \\cdot \\theta - y^{i})^2 $$\n",
    "\n",
    "3. Take the partial derivative with respect to $\\theta_j$:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} (\\text{error}^{i})^2 = 2 (x^{i} \\cdot \\theta - y^{i}) x_j^{i} $$\n",
    "\n",
    "4. The above result gives us the gradient of a single squared error term. To get the gradient for the MSE, we need to average over all $n$ training examples and account for the $\\frac{1}{2}$ term in front (which conveneniently reduces to 1):\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "5. The above equation can also be written in matrix form as:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{n} X^T (H_{\\Theta}(X) - Y) = \\frac{1}{n} X^T (X\\Theta - Y)  $$\n",
    "\n",
    "---\n",
    "\n",
    "#### __Gradient of the Cost Function__:\n",
    "\n",
    "To perform gradient descent, we need the gradient of the cost function with respect to our weights, $\\theta$. The gradient will tell us how to update $\\theta$ to reduce our cost.\n",
    "\n",
    "For each weight $\\theta_j$, the partial derivative is:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "#### __Gradient Descent Update Rule__:\n",
    "\n",
    "Given the above gradient, the update rule for gradient descent is:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) $$\n",
    "Where:\n",
    "- $\\alpha$ is our __learning rate__.\n",
    "\n",
    "\n",
    "Substituting in our derived gradient:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{1}{n} \\sum_{i=1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "This update rule is applied simultaneously for all values of $j$.\n",
    "\n",
    "$:=$ simply means the left side of the equation is updated by the right side of the equation (not the other way around)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "And that gives us the gradient for mean squared error!\n",
    "\n",
    "Let's define that function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_and_update(x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float) -> tuple([float, np.ndarray]):\n",
    "    gradient = (1 / len(y)) * x.T @ ((x @ theta) - y) # use the above formula to calculate the gradient of the loss\n",
    "    theta_new = theta - (alpha * gradient) # update the parameters according to our update function\n",
    "    loss = mean_squared_error(x, y, theta_new) # find the new loss\n",
    "    return loss, theta_new\n",
    "\n",
    "# test it out\n",
    "loss, _ = calculate_gradient_and_update(x, y, theta, 0.01)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put it all together and perform *batch gradient descent*\n",
    "\n",
    "Batch gradient descent entails calculating the loss over the entire training dataset. This is only possible if your dataset can fit into memory, but guarantees convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's regenerate our dataset for convenience\n",
    "x, y, theta_true = generate_dataset(d, n, 1)\n",
    "\n",
    "print(f'Our dataset consists of {n} training samples and {d} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = [] # track our losses as we update\n",
    "num_iterations = 100 # how many times we update our parameters\n",
    "ALPHA = 0.1 # learning rate, this value is usually way smaller for nonlinear models (like 1e-4)\n",
    "\n",
    "theta = np.random.uniform(-2,2,(d)) # initialize our starting weights\n",
    "\n",
    "for t in range(num_iterations):\n",
    "    # in batch gradient descent, we perform the weight update once for the entire training data (all 30 samples of x)\n",
    "    loss, theta = calculate_gradient_and_update(x, y, theta, ALPHA)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "print(f'Final loss: {loss}')\n",
    "\n",
    "# plot the losses over time\n",
    "plt.figure(0)\n",
    "plt.plot(loss_history);\n",
    "plt.title('Training loss');\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');\n",
    "\n",
    "# did we recover the true weights?\n",
    "plt.figure(1)\n",
    "plt.plot(range(d), theta_true, color = 'black', marker = 'o', linestyle = 'None')\n",
    "plt.plot(range(d), theta, color = 'red', marker = 'x', linestyle = 'None')\n",
    "plt.xticks([i for i in range(d)])\n",
    "plt.xlabel('theta #')\n",
    "plt.ylabel('theta value')\n",
    "plt.legend(['True weights','Learned weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss is plateauing at some value. Why doesn't it drop to zero? What is the significance of this value? Why can't we recover the true weights? \n",
    "\n",
    "Let's do a little experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our noise in our dataset relate to our final loss? Well, we can easily plot them against each other so let's start there\n",
    "noises = np.arange(0,2,0.01) # create an array of noises ranging from 0 to 2, with steps of 0.01\n",
    "num_iterations = 10\n",
    "learning_rate = 1 # set this to a unreasonably large number because we are optimizing a convex function and want to converge fast\n",
    "final_losses = []\n",
    "\n",
    "for noise in noises:\n",
    "    x,y,true_weights = generate_dataset(d, n, noise)\n",
    "    theta = np.random.uniform(-2,2,(d))\n",
    "    for i in range(num_iterations):\n",
    "        loss, theta = calculate_gradient_and_update(x, y, theta, 1)\n",
    "    final_losses.append(loss)\n",
    "\n",
    "#now plot our final losses against our dataset noise\n",
    "plt.scatter(noises, final_losses)\n",
    "plt.title('Influence of noise on loss')\n",
    "plt.xlabel('Noise amplitude')\n",
    "plt.ylabel('Final loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work through these problems and discuss your answers.\n",
    "\n",
    "*1. Derive the relationship you see here, given what you know about our loss function. (Hint: how did we generate y from x?)* <br>\n",
    "*2. How does the distribution of our training data and weights relate to the amplitude of noise? What common engineering concept can be applied to describe this?* <br>\n",
    "*3. How do you know your model has learned to approximate some real world function, and not just noise?* <br>\n",
    "<br>\n",
    "(FYI, this type of noise in our data is called *aleatoric uncertainty* because it cannot be reduced by collecting more data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Batch vs Stochastic Gradient Descent\n",
    "\n",
    "Batch gradient descent requires computation of the gradient for every sample of your training data, before updating your parameters. However, this can be computationally inefficient. Stochastic gradient descent (SGD) entails learning on each sample, one at a time. Your model will learn much faster, but runs the risk of destabilizing due to noisy inputs.\n",
    "\n",
    "Let's adapt the above code to do SGD on our dataset, and observe our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's regenerate our dataset for convenience\n",
    "x, y, theta_true = generate_dataset(d, n, 1)\n",
    "\n",
    "loss_history = []\n",
    "num_epochs = 10 # how many times we iterate through our whole dataset, element by element\n",
    "# note: epoch and iteration is different. iteration is the number of times required to go through all training samples. \n",
    "# epoch is when all iterations of training samples have been completed.\n",
    "ALPHA = 0.1 \n",
    "\n",
    "theta = np.random.uniform(-2,2,(d)) # initialize our starting weights\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for i in range(len(x)):\n",
    "        # note: see how the x and y inputs to this function is different in this case (SGD) than that of batch gradient descent above. \n",
    "        # in the case of batch gradient descent, we fed in the entire 30 samples of x and y matrices,\n",
    "        # whereas in the case of SGD here, we only feed in x and y one sample at a time\n",
    "        loss, theta = calculate_gradient_and_update(np.expand_dims(x[i,:],0), np.expand_dims(y[i],0), theta, ALPHA) # we update the size \n",
    "        loss_history.append(loss)\n",
    "\n",
    "# The function calculate_gradient_and_update takes in x and y as 2-dimensional arrays.\n",
    "# We need to reshape x[i,:] and y[i] from (i,) to (1,i) or (sample, feature) using np.expand_dims(x[i,:],0)\n",
    "print(f'Shape of x before expansion {np.shape(x[i,:])}')\n",
    "print(f'Shape of x after np.expand_dims {np.shape(np.expand_dims(x[i,:],0))}')\n",
    "\n",
    "print(f'Final loss: {loss}')\n",
    "\n",
    "# plot the losses over time\n",
    "plt.figure(0)\n",
    "plt.plot(loss_history);\n",
    "plt.title('Training loss');\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');\n",
    "\n",
    "# did we recover the true weights?\n",
    "plt.figure(1)\n",
    "plt.plot(range(d), theta_true, color = 'black', marker = 'o', linestyle = 'None')\n",
    "plt.plot(range(d), theta, color = 'red', marker = 'x', linestyle = 'None')\n",
    "plt.xticks([i for i in range(d)])\n",
    "plt.xlabel('theta #')\n",
    "plt.ylabel('theta value')\n",
    "plt.legend(['True weights','Learned weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Why do you see a repeated pattern in the loss curve?* <br>\n",
    "*2. Why is it harder to converge to the true weights?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Visualize learning\n",
    "\n",
    "A visual example of how batch gradient descent and stochastic gradient descent differ can be useful to see. Let's regenerate our dataset, now with just 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our dataset\n",
    "x, y, theta_true = generate_dataset(2, n, 1)\n",
    "starting_theta = np.random.uniform(-2,2,(2)) #initialize our starting weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train on this new dataset using both methods. Make sure to start from the same initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Gradient Descent\n",
    "theta_history_batch = [] # track our parameters as we update them\n",
    "num_iterations = 100 # how many times we update our parameters\n",
    "ALPHA = 0.1 # learning rate, this value is usually way smaller for nonlinear models (like 1e-4)\n",
    "\n",
    "theta = starting_theta\n",
    "for t in range(num_iterations):\n",
    "    _, theta = calculate_gradient_and_update(x, y, theta, ALPHA)\n",
    "    theta_history_batch.append(theta)\n",
    "\n",
    "theta_history_batch = np.array(theta_history_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "theta_history_sgd = []\n",
    "num_epochs = 10 # how many times we iterate through our whole dataset, element by element\n",
    "ALPHA = 0.1 \n",
    "\n",
    "theta = starting_theta\n",
    "for e in range(num_epochs):\n",
    "    for i in range(len(x)):\n",
    "        _, theta = calculate_gradient_and_update(np.expand_dims(x[i,:],0), np.expand_dims(y[i],0), theta, ALPHA) # we update the size \n",
    "        theta_history_sgd.append(theta)\n",
    "\n",
    "theta_history_sgd = np.array(theta_history_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the trajectory of our parameters as it travels over the loss landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the loss landscape\n",
    "\n",
    "# create the coordinates\n",
    "param_space = np.linspace(-2,2,100) # define our grid of points to evaluate\n",
    "theta0, theta1 = np.meshgrid(param_space, param_space)\n",
    "loss_scape = []\n",
    "\n",
    "# create the colors / contour\n",
    "# essentially this is taking 100x100 values of theta, calculate the loss for each of those pairs, and seeing which combo results in the lowest loss\n",
    "for t0, t1 in zip(np.ravel(theta0), np.ravel(theta1)): # for every coordinate in our grid\n",
    "    l, _ = calculate_gradient_and_update(x,y,np.array([t0,t1]),1) # calculate loss\n",
    "    loss_scape.append(l)\n",
    "loss_scape = np.array(loss_scape).reshape(theta0.shape) # get it back in proper shape\n",
    "\n",
    "# plot the loss landscape and each training method\n",
    "plt.figure(0, figsize = (12,12))\n",
    "plt.title('Parameter Optimization', fontsize = 20)\n",
    "plt.contourf(theta0, theta1, loss_scape, levels=np.logspace(-2, 3, 100), cmap = 'inferno')\n",
    "plt.clim(np.min(loss_scape),np.max(loss_scape))\n",
    "plt.colorbar()\n",
    "plt.xlabel('$theta_0$')\n",
    "plt.ylabel('$theta_1$')\n",
    "\n",
    "plt.plot(theta_history_sgd[:,0],theta_history_sgd[:,1], color = 'white', label = 'SGD')\n",
    "plt.plot(theta_history_batch[:,0],theta_history_batch[:,1], color = 'cyan', label = 'Batch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk through and code up answers to the following questions.\n",
    "\n",
    "*1. Implement a learning rate scheduler for stochastic gradient descent.* <br>\n",
    "*2. How do you make a scheduler sensitive to learning in real time? Think of the trajectory in physics terms.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (BONUS) Problem 4: Gradient descent with a nonlinear function\n",
    "\n",
    "Real world data is almost always nonlinear. Though we have not yet covered nonlinear models, it is frequent practice to apply a linear model to nonlinear datasets. Let's use a classic function, Himmelblau's function.\n",
    "\n",
    "$$f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2$$\n",
    "\n",
    "It is commonly used for testing optimization algorithms because it has multiple local minima. To perform gradient descent directly on this function, you need to find the partial derivatives of $f(x, y)$ in terms of both $x$ and $y$. To be clear, there is no cost function to plug in here, we are using the derivative of the Himmelblau function directly as our cost function or **objective function** and minimizing it!\n",
    "\n",
    "Try deriving these yourself and plugging them in to the code below. Then, the code below shows how gradient descent can result in very different solutions, depending on initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#t ry updating this and seeing how the trajectory changes\n",
    "STARTING_COORDS = (0,0)\n",
    "\n",
    "def himmelblau(x, y):\n",
    "    return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n",
    "\n",
    "def himmelblau_gradient_descent(lr=0.01, n_iterations=1000, init_point=(-4, 4)):\n",
    "    x, y = init_point\n",
    "    history = [(x, y)]\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        gradient_x = # ADD YOUR CODE HERE\n",
    "        gradient_y = # ADD YOUR CODE HERE\n",
    "        \n",
    "        x -= lr * gradient_x\n",
    "        y -= lr * gradient_y\n",
    "        \n",
    "        history.append((x, y))\n",
    "        \n",
    "    return np.array(history)\n",
    "\n",
    "history = himmelblau_gradient_descent(lr=0.01, n_iterations=100, init_point=(0,0)) # why does increasing learning rate throw an error?\n",
    "\n",
    "# Visualizing the optimization path\n",
    "x = np.linspace(-6, 6, 400)\n",
    "y = np.linspace(-6, 6, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = himmelblau(X, Y)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(X, Y, Z, 50, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.plot(history[:, 0], history[:, 1], c='red')  # plotting the path\n",
    "plt.title(\"Gradient Descent on Himmelblau's Function\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
