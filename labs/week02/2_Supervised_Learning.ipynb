{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Let's implement least means square fitting manually, and check to see how different parameters affect learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) OLS\n",
    "Taken from https://github.com/jermwatt/machine_learning_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "csvname =  'student_debt_data.csv'\n",
    "data = np.loadtxt(csvname,delimiter=',')\n",
    "\n",
    "# extract input - for this dataset, these are times\n",
    "x = data[:,0]\n",
    "\n",
    "# extract output - for this dataset, these are total student debt\n",
    "y = data[:,1]\n",
    "\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) LMS\n",
    "### Create a pseudo-random dataset\n",
    "\n",
    "Given the tensor `x` in space $\\mathbb{R}^{\\text{j}}$ with `i` samples and `j` features, generate `y` such that it holds some correlation to `x`.\n",
    "\n",
    "A *tensor* is simple a generalized matrix that can be any dimension, not just 2D. We will stick with 2D here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "J = 5 # num features\n",
    "I = 30 # num samples in dataset\n",
    "NOISE_AMPLITUDE = 0.1 # how much noise to inject into dataset\n",
    "\n",
    "# Generate x values\n",
    "x = np.random.uniform(-1, 1, (I,J))\n",
    "print(f'Shape of array x is {x.shape}') # check the shape\n",
    "\n",
    "# Generate a y value that is somewhat correlated\n",
    "# There are many ways to do this, let's just write a quick rule that linearly combines the features of x and injects some noise\n",
    "# Note that we assume an intercept (bias) of 0\n",
    "true_weights = np.random.uniform(-1,1, (J))\n",
    "\n",
    "# WHAT IS GOIG ON HERE?\n",
    "y = x @ true_weights + np.random.normal(0,NOISE_AMPLITUDE,(I)) # the `@` operator is used for numpy matrix multiplication, and is just shorthand for the dot product\n",
    "\n",
    "# WHAT SHOULD THE CORR BE?\n",
    "# Let's check the correlation to be sure\n",
    "correlations = [np.corrcoef(x[:, i], y)[0, 1] for i in range(J)] # calculate Pearson's R for each feature vector\n",
    "print(f'Correlations for each feature are {correlations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are, some features will have a large correlation whereas others may have little correlation. Note that correlation here is only checking for the existence of a *linear* relationship.\n",
    "\n",
    "If we wanted to improve our correlations, is it better to add more data or to reduce the amplitude of noise? Come up with a hypothesis and test it by tuning the parameters above.\n",
    "\n",
    "Experiment with the number of samples, features, and amplitude of noise.\n",
    "\n",
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 1*J))\n",
    "\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, J)) # make an iterable of colors\n",
    "\n",
    "for feature in range(J):\n",
    "    plt.subplot(1, J, feature+1)\n",
    "    plt.scatter(x[:,feature],y,color = colors[feature])\n",
    "    plt.title(f\"Feature {feature+1}\")\n",
    "    plt.xlabel(f\"$x_{feature+1}$\")\n",
    "    plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease of use later, let's wrap up our dataset generation into a function that gives us an x and y given our starting params\n",
    "\n",
    "def generate_dataset(num_feats: int, num_samples: int, noise_amp: float) -> tuple([np.ndarray, np.ndarray, np.ndarray]):\n",
    "    x = np.random.uniform(-1, 1, (num_samples, num_feats))\n",
    "    true_weights = np.random.uniform(-1,1, (num_feats))\n",
    "    y = x @ true_weights + np.random.normal(0, noise_amp, (num_samples))\n",
    "    return x, y, true_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Mean Squares\n",
    "\n",
    "We will now implement LMS to see if we can recover our true weights!\n",
    "\n",
    "We can start by taking a random guess of our true weights. Let's call our random starting weights `θ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.uniform(-2,2,(J)) # here, we are initializing our weights from a uniform distribution ranging from -2 to 2, but it could start from anywhere\n",
    "print(f'theta is {theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply those weights `θ` (our hypothesis) to our data `x` to calculate our predicted y, or $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = x @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define the LMS cost function. Here, our cost function we would like to minimize is the *mean squared error* between y and yhat. Let's write a function so that this is easy to compute. We will use good coding practice here as well by properly documenting our function with typings and naming our variables to be easily understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(x : np.ndarray, y : np.ndarray, theta : np.ndarray) -> np.ndarray:\n",
    "    yhat = x @ theta # apply weights to data to get prediction yhat\n",
    "    error = yhat - y # get the error\n",
    "    loss = (1 / len(y)) * np.sum(error ** 2) #mean squared error\n",
    "    return loss\n",
    "\n",
    "# test it out\n",
    "print(f'Initial loss: {mean_squared_error(x,y,theta)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do gradient descent. This is an iterative algorithm that requires us to take the partial derivative of our loss function, with respect to our parameters θ. Below is the derivation provided again for review.\n",
    "\n",
    "---\n",
    "\n",
    "#### __Cost Function__:\n",
    "\n",
    "The cost function for LMS is defined as the Mean Squared Error (MSE):\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$\n",
    "Where:\n",
    "- $m$ is the number of data points.\n",
    "- $h_{\\theta}(x^{(i)})$ is our hypothesis or prediction for the $i^{th}$ input. \n",
    "\n",
    "---\n",
    "\n",
    "#### __Hypothesis__:\n",
    "\n",
    "Our hypothesis function is given by:\n",
    "\n",
    "$$ h_{\\theta}(x) = x \\cdot \\theta $$\n",
    "Where:\n",
    "- $x$ is our input vector.\n",
    "- $\\theta$ is our weight vector.\n",
    "\n",
    "---\n",
    "\n",
    "#### __Gradient of the Cost Function__:\n",
    "\n",
    "To perform gradient descent, we need the gradient of the cost function with respect to our weights, $\\theta$. The gradient will tell us how to update $\\theta$ to reduce our cost.\n",
    "\n",
    "For each weight $\\theta_j$, the partial derivative is:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "#### __Gradient Descent Update Rule__:\n",
    "\n",
    "Given the above gradient, the update rule for gradient descent is:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) $$\n",
    "Where:\n",
    "- $\\alpha$ is our __learning rate__.\n",
    "\n",
    "\n",
    "Substituting in our derived gradient:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "This update rule is applied simultaneously for all values of $j$.\n",
    "\n",
    "$:=$ simply means the left side of the equation is updated by the right side of the equation (not the other way around)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### __Derivation of the Gradient__:\n",
    "\n",
    "Now, for the step-by-step derivation of the gradient:\n",
    "\n",
    "1. Start with a single example $i$ inside the summation:\n",
    "\n",
    "$$ \\text{error}^{i} = h_{\\theta}(x^{i}) - y^{i} $$\n",
    "\n",
    "2. Squared error for the $i^{th}$ example:\n",
    "\n",
    "$$ (\\text{error}^{i})^2 = (x^{i} \\cdot \\theta - y^{i})^2 $$\n",
    "\n",
    "3. Take the partial derivative with respect to $\\theta_j$:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} (\\text{error}^{i})^2 = 2 (x^{i} \\cdot \\theta - y^{i}) x_j^{i} $$\n",
    "\n",
    "4. The above result gives us the gradient of a single squared error term. To get the gradient for the MSE, we need to average over all $m$ training examples and account for the $\\frac{1}{2}$ term in front (which conveneniently reduces to 1):\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} $$\n",
    "\n",
    "And that gives us the gradient for mean squared error!\n",
    "\n",
    "Let's define that function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_and_update(x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float) -> tuple([float, np.ndarray]):\n",
    "    gradient = (1 / len(y)) * x.T @ ((x @ theta) - y) # use the above formula to calculate the gradient of the loss\n",
    "    theta_new = theta - (alpha * gradient) # update the parameters according to our update function\n",
    "    loss = mean_squared_error(x, y, theta_new) # find the new loss\n",
    "    return loss, theta_new\n",
    "\n",
    "# test it out\n",
    "loss, _ = calculate_gradient_and_update(x, y, theta, 0.01)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put it all together and perform *batch gradient descent*\n",
    "\n",
    "Batch gradient descent entails calculating the loss over the entire training dataset. This is only possible if your dataset can fit into memory, but guarantees convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's regenerate our dataset for convenience\n",
    "x, y, true_weights = generate_dataset(J, I, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = [] #track our losses as we update\n",
    "num_iterations = 100 #how many times we update our parameters\n",
    "ALPHA = 0.1 #learning rate, this value is usually way smaller for nonlinear models (like 1e-4)\n",
    "\n",
    "theta = np.random.uniform(-2,2,(J)) #initialize our starting weights\n",
    "\n",
    "for t in range(num_iterations):\n",
    "    loss, theta = calculate_gradient_and_update(x, y, theta, ALPHA)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "print(f'Final loss: {loss}')\n",
    "\n",
    "# plot the losses over time\n",
    "plt.figure(0)\n",
    "plt.plot(loss_history);\n",
    "plt.title('Training loss');\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');\n",
    "\n",
    "#did we recover the true weights?\n",
    "plt.figure(1)\n",
    "plt.scatter(range(J),true_weights, color = 'black')\n",
    "plt.scatter(range(J), theta, color = 'red', marker = 'x')\n",
    "plt.legend(['True weights','Learned weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss is plateauing at some value. Why doesn't it drop to zero? What is the significance of this value? Why can't we recover the true weights? \n",
    "\n",
    "Let's do a little experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our noise in our dataset relate to our final loss? Well, we can easily plot them against each other so let's start there\n",
    "noises = np.arange(0,2,0.01)\n",
    "num_iterations = 10\n",
    "learning_rate = 1 #set this to a unreasonably large number because we are optimizing a convex function and want to converge fast\n",
    "final_losses = []\n",
    "\n",
    "for n in noises:\n",
    "    x,y,true_weights = generate_dataset(J, I, n)\n",
    "    theta = np.random.uniform(-2,2,(J))\n",
    "    for i in range(num_iterations):\n",
    "        loss, theta = calculate_gradient_and_update(x, y, theta, 1)\n",
    "    final_losses.append(loss)\n",
    "\n",
    "#now plot our final losses against our dataset noise\n",
    "plt.scatter(noises, final_losses)\n",
    "plt.title('Influence of noise on loss')\n",
    "plt.xlabel('Noise amplitude')\n",
    "plt.ylabel('Final loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work through these problems and discuss your answers.\n",
    "\n",
    "1. Derive the relationship you see here, given what you know about our loss function.\n",
    "2. How does the distribution of our training data and weights relate to the amplitude of noise? What common engineering concept can be applied to describe this?\n",
    "3. How do you know your model has learned to approximate some real world function, and not just noise?\n",
    "\n",
    "(fyi, this type of noise in our data is called *aleatoric uncertainty* because it cannot be reduced by collecting more data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Batch vs Stochastic Gradient Descent\n",
    "\n",
    "Batch gradient descent requires computation of the gradient for every sample of your training data, before updating your parameters. However, this can be computationally inefficient. Stochastic gradient descent (SGD) entails learning on each sample, one at a time. Your model will learn much faster, but runs the risk of destabilizing due to noisy inputs.\n",
    "\n",
    "Let's adapt the above code to do SGD on our dataset, and observe our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's regenerate our dataset for convenience\n",
    "x, y, true_weights = generate_dataset(J, I, 1)\n",
    "\n",
    "loss_history = []\n",
    "num_epochs = 10 # how many times we iterate through our whole dataset, element by element\n",
    "ALPHA = 0.1 \n",
    "\n",
    "theta = np.random.uniform(-2,2,(J)) # initialize our starting weights\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for i in range(len(x)):\n",
    "        loss, theta = calculate_gradient_and_update(np.expand_dims(x[i,:],0), np.expand_dims(y[i],0), theta, ALPHA) # we update the size \n",
    "        loss_history.append(loss)\n",
    "\n",
    "print(f'Final loss: {loss}')\n",
    "\n",
    "# plot the losses over time\n",
    "plt.figure(0)\n",
    "plt.plot(loss_history);\n",
    "plt.title('Training loss');\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');\n",
    "\n",
    "#did we recover the true weights?\n",
    "plt.figure(1)\n",
    "plt.scatter(range(J),true_weights, color = 'black')\n",
    "plt.scatter(range(J), theta, color = 'red', marker = 'x')\n",
    "plt.legend(['True weights','Learned weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you see a repeated pattern in the loss curve? Why is it harder to converge to the true weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Visualize learning\n",
    "\n",
    "A visual example of how batch gradient descent and stochastic gradient descent differ can be useful to see. Let's regenerate our dataset, now with just 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make our dataset\n",
    "x, y, true_weights = generate_dataset(2, I, 1)\n",
    "starting_theta = np.random.uniform(-2,2,(2)) #initialize our starting weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train on this new dataset using both methods. Make sure to start from the same initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform batch gradient descent\n",
    "theta_history_batch = [] #track our parameters as we update them\n",
    "num_iterations = 100 #how many times we update our parameters\n",
    "ALPHA = 0.1 #learning rate, this value is usually way smaller for nonlinear models (like 1e-4)\n",
    "\n",
    "theta = starting_theta\n",
    "for t in range(num_iterations):\n",
    "    _, theta = calculate_gradient_and_update(x, y, theta, ALPHA)\n",
    "    theta_history_batch.append(theta)\n",
    "\n",
    "theta_history_batch = np.array(theta_history_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat now with SGD\n",
    "theta_history_sgd = []\n",
    "num_epochs = 10 #how many times we iterate through our whole dataset, element by element\n",
    "ALPHA = 0.1 \n",
    "\n",
    "theta = starting_theta\n",
    "for e in range(num_epochs):\n",
    "    for i in range(len(x)):\n",
    "        _, theta = calculate_gradient_and_update(np.expand_dims(x[i,:],0), np.expand_dims(y[i],0), theta, ALPHA) #we update the size \n",
    "        theta_history_sgd.append(theta)\n",
    "\n",
    "theta_history_sgd = np.array(theta_history_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the trajectory of our parameters as it travels over the loss landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the loss landscape\n",
    "param_space = np.linspace(-2,2,100) #define our grid of points to evaluate\n",
    "theta0, theta1 = np.meshgrid(param_space, param_space)\n",
    "loss_scape = []\n",
    "\n",
    "for t0, t1 in zip(np.ravel(theta0), np.ravel(theta1)): #for every coordinate in our grid\n",
    "    l, _ = calculate_gradient_and_update(x,y,np.array([t0,t1]),1) #calculate loss\n",
    "    loss_scape.append(l)\n",
    "loss_scape = np.array(loss_scape).reshape(theta0.shape) #get it back in proper shape\n",
    "\n",
    "#plot the loss landscape and each training method\n",
    "plt.figure(0, figsize = (12,12))\n",
    "plt.title('Parameter Optimization', fontsize = 20)\n",
    "plt.contourf(theta0, theta1, loss_scape, levels=np.logspace(-2, 3, 100), cmap = 'inferno')\n",
    "plt.clim(np.min(loss_scape),np.max(loss_scape))\n",
    "plt.colorbar()\n",
    "plt.xlabel('theta_0')\n",
    "plt.ylabel('theta_1')\n",
    "plt.plot(theta_history_sgd[:,0],theta_history_sgd[:,1], color = 'white')\n",
    "plt.plot(theta_history_batch[:,0],theta_history_batch[:,1], color = 'cyan')\n",
    "\n",
    "plt.legend(['SGD','Batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk through and code up answers to the following questions.\n",
    "\n",
    "1. Implement a learning rate scheduler for stochastic gradient descent.\n",
    "2. How do you make a scheduler sensitive to learning in real time? Think of the trajectory in physics terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (BONUS) Problem 4: Gradient descent with a nonlinear function\n",
    "\n",
    "Real world data is almost always nonlinear. Though we have not yet covered nonlinear models, it is frequent practice to apply a linear model to nonlinear datasets. Let's use a classic function, Himmelblau's function.\n",
    "\n",
    "$$f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2$$\n",
    "\n",
    "It is commonly used for testing optimization algorithms because it has multiple local minima. To perform gradient descent directly on this function, you need to find the partial derivatives of $f(x, y)$ in terms of both $x$ and $y$. To be clear, there is no cost function to plug in here, we are using the derivative of the Himmelblau function directly as our cost function or **objective function** and minimizing it!\n",
    "\n",
    "Try deriving these yourself and plugging them in to the code below. Then, the code below shows how gradient descent can result in very different solutions, depending on initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#try updating this and seeing how the trajectory changes\n",
    "STARTING_COORDS = (0,0)\n",
    "\n",
    "def himmelblau(x, y):\n",
    "    return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n",
    "\n",
    "def himmelblau_gradient_descent(lr=0.01, n_iterations=1000, init_point=(-4, 4)):\n",
    "    x, y = init_point\n",
    "    history = [(x, y)]\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        gradient_x = # put solution here\n",
    "        gradient_y = # put solution here\n",
    "        \n",
    "        x -= lr * gradient_x\n",
    "        y -= lr * gradient_y\n",
    "        \n",
    "        history.append((x, y))\n",
    "        \n",
    "    return np.array(history)\n",
    "\n",
    "history = himmelblau_gradient_descent(lr=0.01, n_iterations=100, init_point=(0,0)) #why does increasing learning rate throw an error?\n",
    "\n",
    "# Visualizing the optimization path\n",
    "x = np.linspace(-6, 6, 400)\n",
    "y = np.linspace(-6, 6, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = himmelblau(X, Y)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(X, Y, Z, 50, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.plot(history[:, 0], history[:, 1], c='red')  # Plotting the path\n",
    "plt.title(\"Gradient Descent on Himmelblau's Function\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try deriving this yourself first.\n",
    "\n",
    "        gradient_x = 4*x*(x**2 + y - 11) + 2*(x + y**2 - 7)\n",
    "        gradient_y = 2*(x**2 + y - 11) + 4*y*(x + y**2 - 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
