{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "How to select features for a machine learning dataset. Feature selection can improve model performance dramatically in some situations, and almost always speeds up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert to DataFrames for easier manipulation\n",
    "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df_housing['MEDV'] = housing.target\n",
    "\n",
    "print(df_housing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A) Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What statistics could you apply to the features for purposes of selection?** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson's R Correlation\n",
    "\n",
    "\\begin{equation}\n",
    "R = \\frac{n \\sum xy - (\\sum x)(\\sum y)}{\\sqrt{[n \\sum x^2 - (\\sum x)^2][n \\sum y^2 - (\\sum y)^2]}}\n",
    "\\end{equation}\n",
    "\n",
    "$R = 1$: Perfect Positive <br>\n",
    "$R > 0.5$: Strong Positive <br>\n",
    "$.3 < R \\leq .5$: Moderate Positive <br>\n",
    "$0 < R \\leq .3$: Weak Positive <br>\n",
    "$R = 0$: None <br>\n",
    "$0 > R \\geq –.3$: Weak Negative <br>\n",
    "$–.3 < R \\geq –.5$: Moderate Negative <br>\n",
    "$R < –.5$: Strong Negative <br>\n",
    "$R = -1$: Perfect Negative <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pearson's R to find correlations with the target variable\n",
    "print(df_housing.corr())\n",
    "\n",
    "plt.imshow(df_housing.corr())\n",
    "\n",
    "features = housing.feature_names + housing.target_names\n",
    "plt.xticks(range(len(features)),labels = features, rotation=45);\n",
    "plt.yticks(range(len(features)),labels = features, rotation=45);\n",
    "plt.colorbar()\n",
    "plt.clim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: From a quick glance, which features seem correlated with median house value?** <br>\n",
    "\n",
    "**Q: Are there any features that could be removed?** <br>\n",
    "\n",
    "**Q: Is there a situation where you would remove a feature, despite it having a good correlation with your target of interest?** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some features that both make sense to use and have some correlation\n",
    "\n",
    "# Split dataset into train and test set\n",
    "\n",
    "# Train a linear regression model for a quick test\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a relevant evaluation metric for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using a proper evaluation metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to a model trained on all features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain a linear regression model on all features, calculate same evaluation metric and compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How is the performance of the model trained with all features and with a subset of features? Explain why** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.B) Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Selection\n",
    "\n",
    "We can use either sklearn's or mlxtend's ```SequentialFeatureSelector()``` class.\n",
    "\n",
    "In mlxtend: <br>\n",
    "```SequentialFeatureSelector()``` class accepts the following major parameters:\n",
    "* ```LinearRegression()``` acts as an estimator for the feature selection process. Alternatively, it can be substituted with other regression or classification based algorithm.\n",
    "* ```k_features``` indicates the number of features to be selected. For demonstration purposes, 5 features are selected from the original 13. This value can be optimized by analyzing the scores for different numbers of features.\n",
    "* ```forward``` indicates the direction of the wrapper method used. ```forward = True``` for forward selection whereas ```forward = False``` for backward elimination.\n",
    "* ```scoring``` argument specifies the evaluation criterion to be used.\n",
    "* ```cv``` argument is for k-fold cross-validation. Be default, it will be set as 5. Bear in mind, a larger number of cross-validation can be time-consuming and computing-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we selected all features to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to do forward selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain a linear regression model on selected features, calculate same evaluation metric and compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using mlxtend library this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we selected all features to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we select the optimal number for k_features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we selected all features to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain a linear regression model on selected features, calculate same evaluation metric and compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.C) Embedded Methods\n",
    "Let's try some Embedded Methods for Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we selected all features to start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization / Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Regularization / Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Compare the performance of the models obtained using Lasso vs Ridge Regression. Explain your observation** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_wine\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Load dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert to DataFrames for easier manipulation\n",
    "df_wine = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df_wine['wine_class'] = wine.target\n",
    "\n",
    "df_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A) Filter Methods\n",
    "**Q: What statistics could you apply to the features for purposes of selection?** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA\n",
    "\n",
    "ANOVA is used to check the means of two or more groups that are significantly different from each other:\n",
    "\n",
    "* $HO$: means of all groups are equal\n",
    "* $H1$: at least one mean of the groups are different\n",
    "\n",
    "ANOVA assumes: 1) linear relationship between the feature and the target, 2) the variables follow a Gaussian distribution.\n",
    "\n",
    "One Way ANOVA tests the relationship between categorical predictor vs continuous response.\n",
    "\n",
    "\\begin{gather}\n",
    "SS_{between} = \\sum_{j=1}^p n_j (x_j - x)^2 \\\\\n",
    "SS_{within} = \\sum_{j=1}^p \\sum_{i=1}^{n_j} (x_{ij} - x_j)^2 \\\\\n",
    "\\\\\n",
    "MS_{between} = \\frac{SS_{between}}{k - 1}\\\\\n",
    "MS_{within} = \\frac{SS_{within}}{N - k}\\\\\n",
    "\\\\\n",
    "F = \\frac{MS_{between}}{MS_{within}}\n",
    "\\end{gather}\n",
    "\n",
    "where: <br>\n",
    "$SS_{between} =$ sum of squares between the groups <br>\n",
    "$SS_{within} =$ sum of squares within the groups <br>\n",
    "$k =$ number of groups <br>\n",
    "$N = $ total number of observations across all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a one way ANOVA for each feature\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real world data collection is expensive. Select the top 3 features to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy leaves some to be desired. What if we search all possible combinations of 3 features to empirically discover the optimal 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "combos = list(combinations(range(len(wine.feature_names)), 3))\n",
    "\n",
    "best = 0.0\n",
    "best_feats = []\n",
    "for combo in combos:\n",
    "    feature_ids = combo\n",
    "    model = LogisticRegression(max_iter=10000).fit(wine.data[:,feature_ids], wine.target)\n",
    "    preds = model.predict(wine.data[:,feature_ids])\n",
    "    mat = confusion_matrix(wine.target, preds)\n",
    "    accuracy = np.trace(mat) / np.sum(mat)\n",
    "    if accuracy > best:\n",
    "        best_feats = combo\n",
    "        best = accuracy\n",
    "print(best_feats, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:If a one way ANOVA was used above to identify features, why did it not work so well?**\n",
    "\n",
    "**Q: What are the pros and cons of searching for the best features by checking model results?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
