{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reseach Perspectives on Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1943 - Perceptron\n",
    "\n",
    "The perceptron was originally a machine made to do binary classification on images. Let's build a little simulation to see if we can get the perceptron to recognize two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#original perceptron was hooked up to ~400 photocells. let's increase ours a bit to 1600 photocells, so images of size 40x40\n",
    "#load in our images\n",
    "img1 = Image.open('img1_bw.jpg')\n",
    "img1 = np.array(img1)\n",
    "print(img1.shape)\n",
    "img2 = Image.open('img2_bw.jpg')\n",
    "img2 = np.array(img2)\n",
    "print(img2.shape)\n",
    "\n",
    "#images are represented as a 2d array of pixel values. lets visualize them\n",
    "plt.figure(0)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.figure(1)\n",
    "plt.imshow(img2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the perceptron worked on binary data, so we need to convert our pixel values to binary values. let's assign a cutoff \n",
    "img1_bin = (img1 > 130).astype(int)\n",
    "img2_bin = (img2 > 130).astype(int)\n",
    "plt.figure(0)\n",
    "plt.imshow(img1_bin, cmap='gray')\n",
    "plt.figure(1)\n",
    "plt.imshow(img2_bin, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation setup\n",
    "\n",
    "The perceptron connected each photosensor to its own \"neuron\". So with an image of size 40x40, we have 1600 photosensors, and thus need 1600 neurons. We will initialize the weights and use the following update rule to train the perceptron.\n",
    "\n",
    "$$Δw_i = η (y - ŷ) x_i$$\n",
    "$$Δb = η (y - ŷ)$$\n",
    "\n",
    "Where:\n",
    "- \\( Δw_i \\) is the change applied to weight \\( i \\)\n",
    "- \\( η \\) is the learning rate\n",
    "- \\( y \\) is the true label\n",
    "- \\( ŷ \\) is the predicted label\n",
    "- \\( x_i \\) is the \\( i \\)-th input value\n",
    "- \\( Δb \\) is the change applied to the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size: int):\n",
    "        self.weights = np.random.normal(0,0.1, (input_size+1)) #add 1 for the bias term, or in this specific case, the \"threshold\"\n",
    "\n",
    "    def step_activation(self, x: np.ndarray):\n",
    "        return 1 if x >= 0 else 0\n",
    "    \n",
    "    def predict(self, inputs: np.ndarray):\n",
    "        potential = np.dot(inputs, self.weights[:-1] + self.weights[-1])\n",
    "        return self.step_activation(potential)\n",
    "    \n",
    "    def train(self, train_data: np.ndarray, labels: np.ndarray, num_epochs: int, learning_rate: float):\n",
    "        for _ in range(num_epochs):\n",
    "            for x,y in zip(train_data, labels):\n",
    "                yhat = self.predict(x)\n",
    "                #apply update rule\n",
    "                self.weights[:-1] += learning_rate * (y - yhat) * x #learn the weights\n",
    "                self.weights[-1] += learning_rate * (y - yhat) #learn the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a perceptron\n",
    "Given our two images, can it recognize which one is which?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize data\n",
    "x = [img1_bin.flatten(), img2_bin.flatten()]\n",
    "y = [0.0, 1.0] #0 for matt, 1 for robin\n",
    "\n",
    "#create an instance of our model from our class\n",
    "model = Perceptron(input_size=1600)\n",
    "\n",
    "#train the model\n",
    "model.train(train_data=x,\n",
    "            labels=y,\n",
    "            num_epochs=10,\n",
    "            learning_rate=0.01)\n",
    "\n",
    "#test if our model learned\n",
    "print(f'Matt = 0, model predicted {model.predict(img1_bin.flatten())}')\n",
    "print(f'Robin = 1, model predicted {model.predict(img2_bin.flatten())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless something terribly unlikely happened, it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1968 - Perceptron - linear vs nonlinear\n",
    "\n",
    "Let's try out two datasets. One will be easliy linearly separable, the other won't. Let's see what the perceptron learns for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "\n",
    "#make a linearly separable 2d dataset\n",
    "x_linear, y_linear = make_blobs(n_samples=100, n_features=2, centers=2)\n",
    "x_linear -= np.mean(x_linear, axis=0)\n",
    "\n",
    "\n",
    "#make a linearly INseparable 2d dataset\n",
    "x_nonlinear, y_nonlinear = make_moons(n_samples = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a perceptron for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = Perceptron(2)\n",
    "model_nonlinear = Perceptron(2)\n",
    "\n",
    "model_linear.train(x_linear, y_linear, 1000, 0.001)\n",
    "model_nonlinear.train(x_nonlinear, y_nonlinear, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize each model's decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title('Linear dataset')\n",
    "plt.scatter(x_linear[:,0], x_linear[:,1], c = y_linear, cmap ='winter')\n",
    "x1_min, x1_max = x_linear[:, 0].min() - 1, x_linear[:, 0].max() + 1\n",
    "x1_values = np.linspace(x1_min, x1_max, 100)\n",
    "x2_values = - (model_linear.weights[1] / model_linear.weights[2]) * x1_values - (model_linear.weights[0] / model_linear.weights[2])\n",
    "plt.plot(x1_values, x2_values, color='black');\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Non-linear dataset')\n",
    "plt.scatter(x_nonlinear[:,0], x_nonlinear[:,1], c = y_nonlinear, cmap ='winter')\n",
    "x1_min, x1_max = x_nonlinear[:, 0].min() - 1, x_nonlinear[:, 0].max() + 1\n",
    "x1_values = np.linspace(x1_min, x1_max, 100)\n",
    "x2_values = - (model_nonlinear.weights[1] / model_nonlinear.weights[2]) * x1_values - (model_nonlinear.weights[0] / model_nonlinear.weights[2])\n",
    "plt.plot(x1_values, x2_values, color='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even a simple nonlinearity in the dataset is enough to make the perceptron's predictions useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1982 - Hopfield Networks\n",
    "\n",
    "Train a hopfield network to recognize handwritten numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the MNIST dataset\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)\n",
    "\n",
    "x = digits['data']\n",
    "x_zeros = (digits['data'][digits['target'] == 0] > 10).astype(int)\n",
    "x_fives = (digits['data'][digits['target'] == 5] > 10).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hopfield network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HopfieldNetwork:      \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.threshold = 0\n",
    "        self.weights = np.zeros((size, size))\n",
    "\n",
    "    def train(self, data):\n",
    "        \"\"\"Train the network's weights based on provided data.\"\"\"\n",
    "        num_samples = len(data)\n",
    "        \n",
    "        # Calculate mean activity\n",
    "        mean_activity = np.mean(data)\n",
    "        \n",
    "        # Calculate weights using the Hebb rule\n",
    "        for sample in tqdm(data):\n",
    "            delta = sample - mean_activity\n",
    "            self.weights += np.outer(delta, delta)\n",
    "        \n",
    "        # Zero out diagonal and normalize by the number of samples\n",
    "        np.fill_diagonal(self.weights, 0)\n",
    "        self.weights /= num_samples\n",
    "\n",
    "    def predict(self, data, iterations=20, threshold=0):\n",
    "        \"\"\"Predict the network's output for given data.\"\"\"\n",
    "        return [self._update(sample, iterations, threshold) for sample in tqdm(data)]\n",
    "    \n",
    "    def _update(self, state, iterations, threshold):\n",
    "        \"\"\"Update the state of the network.\"\"\"\n",
    "        energies = []\n",
    "        states = []\n",
    "        prev_energy = self._energy(state)\n",
    "        energies.append(prev_energy)\n",
    "        for _ in range(iterations):\n",
    "            for _ in range(self.size):\n",
    "                idx = np.random.randint(0, self.size)\n",
    "                state[idx] = np.sign(self.weights[idx].T @ state - threshold)\n",
    "                energies.append(self._energy(state))\n",
    "                states.append(state.copy())\n",
    "            if self._energy(state) == prev_energy:\n",
    "                break\n",
    "        return states, energies\n",
    "    \n",
    "    def _energy(self, state):\n",
    "        \"\"\"Calculate the energy of the current state.\"\"\"\n",
    "        return -0.5 * state @ self.weights @ state + np.sum(state * self.threshold)\n",
    "\n",
    "    def plot_weights(self):\n",
    "        \"\"\"Visualize the network's weights.\"\"\"\n",
    "        plt.imshow(self.weights, cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Network Weights\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HopfieldNetwork(64) #8x8 images\n",
    "model.train(x_zeros) #train on ONLY zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model capabilities\n",
    "If we initialize the model \"state\" with a different digit, does it converge to a zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([(x[1] > 10).astype(int)])\n",
    "plt.figure(0)\n",
    "plt.title('Initial input (1)', fontsize=20)\n",
    "plt.imshow(np.reshape(test_input, (8,8)), cmap ='gray');\n",
    "\n",
    "plt.figure(1)\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,5));\n",
    "fig.suptitle('Model activations', fontsize=20)\n",
    "states, energy = model.predict(test_input.copy(), iterations=5)[0]\n",
    "for s in range(5):\n",
    "    axs[s].imshow(np.reshape(states[s*64],(8,8)), cmap='gray');\n",
    "\n",
    "plt.figure(5, figsize=(20,5))\n",
    "plt.title('Model energy', fontsize=20)\n",
    "plt.ylabel('Energy')\n",
    "plt.xlabel('Update Step')\n",
    "plt.plot(energy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model tends to fall into a stable energy state, which we have learned to represent \"zero\". It memorizes the patterns it sees, and encodes them as weights!\n",
    "\n",
    "They are not very powerful at recognizing patterns compared to modern methods, but the concepts here are quite deep."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
